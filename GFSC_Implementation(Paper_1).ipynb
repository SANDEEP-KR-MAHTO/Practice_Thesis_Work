{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW4bToMJWJC0",
        "outputId": "608ab001-663e-4027-c30e-f98501fdc222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing eig1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile eig1.py\n",
        "\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "\n",
        "def eig1(A,c,isMax, isSym):\n",
        "  n = A.shape[0]\n",
        "  if c is None or c > n:\n",
        "    c = n\n",
        "\n",
        "  if isSym:\n",
        "    A = np.maximum(A,A.T)\n",
        "\n",
        "  eigvals, eigvecs = np.linalg.eigh(A)\n",
        "\n",
        "  if isMax == 0:\n",
        "    idx = np.argsort(eigvals)\n",
        "  else:\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "  idx1 = idx[0:c]\n",
        "  eigval = eigvals[idx1]\n",
        "  eigvec = eigvecs[:,idx1]\n",
        "  eigval_full = eigvals[idx]\n",
        "\n",
        "  return eigvec, eigval, eigval_full"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ClusteringMeasure.py\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "def MutualInfo(L1, L2):\n",
        "    \"\"\"Compute Normalized Mutual Information (NMI) between two clusterings.\"\"\"\n",
        "    L1 = L1.flatten()\n",
        "    L2 = L2.flatten()\n",
        "    if L1.shape != L2.shape:\n",
        "        raise ValueError(\"size(L1) must == size(L2)\")\n",
        "\n",
        "    # shift to start from 0\n",
        "    L1 = L1 - np.min(L1)\n",
        "    L2 = L2 - np.min(L2)\n",
        "    nClass = max(L1.max(), L2.max()) + 1\n",
        "\n",
        "    # contingency table\n",
        "    G = np.zeros((nClass, nClass))\n",
        "    for i in range(nClass):\n",
        "        for j in range(nClass):\n",
        "            G[i, j] = np.sum((L1 == i) & (L2 == j)) + np.finfo(float).eps\n",
        "\n",
        "    sumG = G.sum()\n",
        "\n",
        "    P1 = G.sum(axis=1) / sumG\n",
        "    P2 = G.sum(axis=0) / sumG\n",
        "\n",
        "    H1 = -np.sum(P1 * np.log2(P1 + 1e-12))\n",
        "    H2 = -np.sum(P2 * np.log2(P2 + 1e-12))\n",
        "\n",
        "    P12 = G / sumG\n",
        "    PPP = P12 / (P1[:, None] * P2[None, :])\n",
        "    PPP[PPP < 1e-12] = 1\n",
        "\n",
        "    MI = np.sum(P12 * np.log2(PPP))\n",
        "    return MI / max(H1, H2)\n",
        "\n",
        "\n",
        "def bestMap(L1, L2):\n",
        "    \"\"\"Permute labels of L2 to match L1 as best as possible using Hungarian algorithm.\"\"\"\n",
        "    L1 = L1.flatten()\n",
        "    L2 = L2.flatten()\n",
        "    if L1.shape != L2.shape:\n",
        "        raise ValueError(\"size(L1) must == size(L2)\")\n",
        "\n",
        "    L1 = L1 - np.min(L1)\n",
        "    L2 = L2 - np.min(L2)\n",
        "    nClass = max(L1.max(), L2.max()) + 1\n",
        "\n",
        "    # contingency matrix\n",
        "    G = np.zeros((nClass, nClass))\n",
        "    for i in range(nClass):\n",
        "        for j in range(nClass):\n",
        "            G[i, j] = np.sum((L1 == i) & (L2 == j))\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(-G)\n",
        "    mapping = dict(zip(col_ind, row_ind))\n",
        "    newL2 = np.array([mapping[label] for label in L2])\n",
        "    return newL2\n",
        "\n",
        "\n",
        "def ClusteringMeasure(Y, predY):\n",
        "    \"\"\"Compute clustering metrics: ACC, NMI, Purity.\"\"\"\n",
        "    Y = Y.flatten().astype(int)\n",
        "    predY = predY.flatten().astype(int)\n",
        "\n",
        "    # Purity\n",
        "    correnum = 0\n",
        "    for ci in np.unique(predY):\n",
        "        incluster = Y[predY == ci]\n",
        "        if incluster.size > 0:\n",
        "            counts = np.bincount(incluster)\n",
        "            correnum += counts.max()\n",
        "    Purity = correnum / len(predY)\n",
        "\n",
        "    # Accuracy via bestMap\n",
        "    mapped_pred = bestMap(Y, predY)\n",
        "    ACC = np.mean(Y == mapped_pred)\n",
        "\n",
        "    # NMI\n",
        "    MIhat = MutualInfo(Y, mapped_pred)\n",
        "    return ACC, MIhat, Purity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O93G18JYWW_V",
        "outputId": "43f46774-c9a0-4d7b-b387-70e9376df495"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ClusteringMeasure.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile multigraph.py\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from eig1 import eig1\n",
        "from ClusteringMeasure import ClusteringMeasure\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def distance(F,n,j):\n",
        "  all = np.zeros(n)\n",
        "  for u in range(n):\n",
        "    all[u] = np.linalg.norm(F[j,:]- F[u,:]) ** 2\n",
        "  return all\n",
        "\n",
        "\n",
        "\n",
        "def multigraph(X,s,alpha, beta, gama):\n",
        "  mv=len(X)\n",
        "  n=X[0].shape[0]\n",
        "  Z=np.eye(n)\n",
        "  Zv=np.tile(Z[:,:,np.newaxis],(1,1,mv))\n",
        "  M=np.tile(Z[:,:,np.newaxis],(1,1,mv))\n",
        "  c=len(np.unique(s))\n",
        "\n",
        "  wv=np.ones(mv)/mv\n",
        "\n",
        "  for i in range(200):\n",
        "    Z[Z<0]=0\n",
        "    Z=(Z+Z.T)/2\n",
        "    Zold = Z\n",
        "    D = np.diag(Z.sum(axis=1))\n",
        "    L = D-Z\n",
        "\n",
        "\n",
        "    F, eigval, eigval_full = eig1(L,c,0,1)\n",
        "\n",
        "\n",
        "    for i in range(mv):\n",
        "      f = X[i]\n",
        "      A = f @ f.T + alpha * np.eye(n) + beta * wv[i] * np.eye(n)\n",
        "      B = beta * wv[i] * Z + f @ f.T\n",
        "      Zv[:,:,i] = np.linalg.solve(A, B)\n",
        "\n",
        "      T = Zv[:,:,i]\n",
        "      T[T<0] = 0\n",
        "      T = (T + T.T)/2\n",
        "      Zv[:,:,i] = T\n",
        "\n",
        "      wv[i] = 1/(2*np.linalg.norm(Zv[:,:,i]-Z, 'fro'))\n",
        "\n",
        "      M[:,:,i] = wv[i] * Zv[:,:,i]\n",
        "\n",
        "    for j in range(n):\n",
        "      all = distance(F,n,j)\n",
        "      Z[:,j]=(np.sum(M[:,j,:],1) - (gama * all.T)/(4* beta)) / np.sum(wv)\n",
        "\n",
        "    rel_change = np.linalg.norm(Z-Zold, 'fro')/ np.linalg.norm(Zold, 'fro')\n",
        "\n",
        "\n",
        "    if i>5 and rel_change < 1e-3:\n",
        "      break\n",
        "\n",
        "\n",
        "  res = np.zeros((10,3))\n",
        "  for i in range(10):\n",
        "    km = KMeans(n_clusters = c, n_init = 1, random_state = i, verbose =0, init = 'k-means++')\n",
        "    km.fit(F)\n",
        "    actual_ids = km.labels_\n",
        "\n",
        "    res[i,:] = ClusteringMeasure(actual_ids, s)\n",
        "\n",
        "  result = np.zeros((3,2))\n",
        "\n",
        "\n",
        "  result[0,0] = np.mean(res[:,0])\n",
        "  result[0,1] = np.std(res[:,0])\n",
        "\n",
        "  result[1,0] = np.mean(res[:,1])\n",
        "  result[1,1] = np.std(res[:,1])\n",
        "\n",
        "  result[2,0] = np.mean(res[:,2])\n",
        "  result[2,1] = np.std(res[:,2])\n",
        "\n",
        "\n",
        "  return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8UekZadWZf8",
        "outputId": "dd082a0f-3788-4f09-f133-14cb8ecdf33e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing multigraph.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run.py\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "from multigraph import multigraph\n",
        "import os\n",
        "\n",
        "\n",
        "def load_mat_file(path):\n",
        "    with h5py.File(path, \"r\") as f:\n",
        "        data_refs = f[\"data\"]\n",
        "        data = []\n",
        "        for i in range(data_refs.shape[0]):\n",
        "            ref = data_refs[i][0]\n",
        "            arr = np.array(f[ref]).T  # transpose -> (n x d)\n",
        "            data.append(arr)\n",
        "        labels = np.array(f[\"labels\"]).squeeze().astype(int)\n",
        "    return data, labels\n",
        "\n",
        "def normalize_views(data):\n",
        "    normed = []\n",
        "    for X in data:\n",
        "        dist = np.max(X) - np.min(X)\n",
        "        m01 = (X - np.min(X)) / dist\n",
        "        Xn = 2 * m01 - 1\n",
        "        normed.append(Xn)\n",
        "    return normed\n",
        "\n",
        "def run_experiment(mat_file=\"reuters_1200.mat\", out_file=\"reuters.txt\"):\n",
        "    data, labels = load_mat_file(mat_file)\n",
        "    data = normalize_views(data)\n",
        "\n",
        "    para1 = [0.01, 1]\n",
        "    para2 = [100, 1000, 2000]\n",
        "    para3 = [0.01]\n",
        "\n",
        "    with open(out_file, \"a\") as fout:\n",
        "        for a in para1:\n",
        "            for b in para2:\n",
        "                for g in para3:\n",
        "                    print(f\"\\nRunning with alpha={a}, beta={b}, gamma={g}\")\n",
        "                    result = multigraph(data, labels, a, b, g)\n",
        "                    line = [a, b, g] + result.flatten(order=\"F\").tolist()\n",
        "                    fout.write(\"\\t\".join(map(str, line)) + \"\\n\")\n",
        "                    print(f'Iteration completed')\n",
        "                    print(\"Result:\", result)\n",
        "    print(f\"\\nResults saved to {out_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_experiment(\"reuters_1200.mat\", \"reuters.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1LNMfOFWb5e",
        "outputId": "70df125a-bc29-494e-cddb-813378b6662a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vYePVCYWpmk",
        "outputId": "9a521dab-ecda-471b-b867-17f0c4ea1f7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running with alpha=0.01, beta=100, gamma=0.01\n",
            "Iteration completed\n",
            "Result: [[2.51166667e-01 6.66666667e-04]\n",
            " [1.17902994e-01 8.13376551e-04]\n",
            " [8.90500000e-01 6.66666667e-04]]\n",
            "\n",
            "Running with alpha=0.01, beta=1000, gamma=0.01\n",
            "Iteration completed\n",
            "Result: [[1.80000000e-01 0.00000000e+00]\n",
            " [1.60501441e-02 3.63878666e-18]\n",
            " [9.84166667e-01 0.00000000e+00]]\n",
            "\n",
            "Running with alpha=0.01, beta=2000, gamma=0.01\n",
            "Iteration completed\n",
            "Result: [[1.80000000e-01 0.00000000e+00]\n",
            " [1.60501441e-02 3.63878666e-18]\n",
            " [9.84166667e-01 0.00000000e+00]]\n",
            "\n",
            "Running with alpha=1, beta=100, gamma=0.01\n",
            "Iteration completed\n",
            "Result: [[0.277      0.02937119]\n",
            " [0.11807414 0.01637719]\n",
            " [0.8155     0.04093559]]\n",
            "\n",
            "Running with alpha=1, beta=1000, gamma=0.01\n",
            "Iteration completed\n",
            "Result: [[0.34883333 0.01840592]\n",
            " [0.18806887 0.00776474]\n",
            " [0.64033333 0.0311876 ]]\n",
            "\n",
            "Running with alpha=1, beta=2000, gamma=0.01\n",
            "Iteration completed\n",
            "Result: [[0.29425    0.02962134]\n",
            " [0.13226457 0.02316597]\n",
            " [0.725      0.07036709]]\n",
            "\n",
            "Results saved to reuters.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8aQAY1T4Wwur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}