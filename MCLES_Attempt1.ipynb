{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMA8F7bxmdte",
        "outputId": "9243fda9-913c-476b-c213-a701371c285b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eig1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile eig1.py\n",
        "\n",
        "\"\"\"\n",
        "eig1.py\n",
        "\n",
        "Port of MATLAB function eig1.m to Python (NumPy).\n",
        "\n",
        "Usage:\n",
        "    eigvec, eigval, eigval_full = eig1(A, c=None, isMax=True, isSym=True)\n",
        "\n",
        "Inputs:\n",
        "    A       : (n, n) array-like square matrix\n",
        "    c       : int, number of eigenpairs to return (default: n)\n",
        "    isMax   : bool, if True return largest eigenvalues, else smallest (default: True)\n",
        "    isSym   : bool, if True treat A as (elementwise) symmetric by doing np.maximum(A, A.T).\n",
        "              If A is truly symmetric, set True to use the faster symmetric solver.\n",
        "\n",
        "Returns:\n",
        "    eigvec      : (n, c) array with eigenvectors corresponding to `eigval` (columns)\n",
        "    eigval      : (c,) array of selected eigenvalues\n",
        "    eigval_full : (n,) array of all eigenvalues (unsorted)\n",
        "\n",
        "Notes:\n",
        "    - For symmetric matrices we use numpy.linalg.eigh (real symmetric).\n",
        "      For general matrices we use numpy.linalg.eig.\n",
        "    - Behavior mirrors original MATLAB code:\n",
        "        * if c is None -> set to n\n",
        "        * if c > n -> set to n\n",
        "        * if isSym True -> A := np.maximum(A, A.T) (elementwise max), matching MATLAB's max(A,A')\n",
        "        * if isMax True -> sort eigenvalues in descending order (largest first)\n",
        "          else -> ascending (smallest first)\n",
        "    - For very large/sparse matrices consider using scipy.sparse.linalg.eigs / eigsh.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "def eig1(A, c: Optional[int] = None, isMax: bool = True, isSym: bool = True\n",
        "        ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    A = np.asarray(A)\n",
        "    if A.ndim != 2 or A.shape[0] != A.shape[1]:\n",
        "        raise ValueError(\"Input A must be a square matrix (n x n).\")\n",
        "\n",
        "    n = A.shape[0]\n",
        "\n",
        "    # default c\n",
        "    if c is None:\n",
        "        c = n\n",
        "    if c > n:\n",
        "        c = n\n",
        "    # ensure booleans\n",
        "    isMax = bool(isMax)\n",
        "    isSym = bool(isSym)\n",
        "\n",
        "    # If requested, symmetrize similar to MATLAB's max(A, A')\n",
        "    if isSym:\n",
        "        # MATLAB used elementwise max(A, A'), replicating that behavior:\n",
        "        A = np.maximum(A, A.T)\n",
        "\n",
        "    # Choose solver\n",
        "    if isSym:\n",
        "        # Use eigh for symmetric/hermitian matrices (real eigenvalues)\n",
        "        eigvals_full, eigvecs = np.linalg.eigh(A)\n",
        "        # numpy.linalg.eigh returns eigenvalues in ascending order\n",
        "    else:\n",
        "        eigvals_complex, eigvecs_complex = np.linalg.eig(A)\n",
        "        # handle possibly complex eigenvalues: keep as complex if present\n",
        "        eigvals_full = eigvals_complex\n",
        "        eigvecs = eigvecs_complex\n",
        "\n",
        "    # If used symmetric branch, variable names differ:\n",
        "    if isSym:\n",
        "        eigvals_full = eigvals_full  # already set above\n",
        "        eigvecs = eigvecs\n",
        "\n",
        "    # Convert to 1-D array\n",
        "    eigvals_full = np.asarray(eigvals_full).ravel()\n",
        "\n",
        "    # Sorting indices\n",
        "    if isMax:\n",
        "        # descending\n",
        "        idx_sorted = np.argsort(eigvals_full)[::-1]\n",
        "    else:\n",
        "        # ascending\n",
        "        idx_sorted = np.argsort(eigvals_full)\n",
        "\n",
        "    # full eigenvalues in Matlab code: d = diag(d); eigval_full = d(idx)\n",
        "    # MATLAB returns d in the original (unsorted) order as eigval_full = d;\n",
        "    # To mirror that we will return eigval_full as eigvals_full (unsorted).\n",
        "    eigval_full = eigvals_full.copy()\n",
        "\n",
        "    # pick top c indices according to sort\n",
        "    idx1 = idx_sorted[:c]\n",
        "\n",
        "    eigval = eigval_full[idx1]\n",
        "\n",
        "    # eigenvectors columns correspond to eigvals in eigvals_full; pick same columns\n",
        "    # Note: if eigenvectors array columns correspond to eigvals in the same order,\n",
        "    # selecting columns by idx1 is correct.\n",
        "    eigvec = eigvecs[:, idx1]\n",
        "\n",
        "    # If eigenvalues/eigenvectors are (numerically) real but complex dtype, cast to real\n",
        "    # if imaginary parts are very small.\n",
        "    if np.iscomplexobj(eigval) or np.iscomplexobj(eigvec):\n",
        "        # check small imaginary parts\n",
        "        if np.allclose(np.imag(eigval), 0, atol=1e-12) and np.allclose(np.imag(eigvec), 0, atol=1e-12):\n",
        "            eigval = np.real(eigval)\n",
        "            eigvec = np.real(eigvec)\n",
        "            eigval_full = np.real(eigval_full)\n",
        "\n",
        "    return eigvec, eigval, eigval_full\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile UpdateS.py\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "update_s.py\n",
        "\n",
        "Port of MATLAB UpdateS.m (from \"Twin Learning for Similarity and Clustering...\") to Python.\n",
        "\n",
        "Function:\n",
        "    Z = update_S(K, F, alpha, beta)\n",
        "\n",
        "For each column j (1..n), we solve the QP:\n",
        "    min_x 0.5 * x^T H x + ff^T x\n",
        "    s.t.  sum(x) = 1\n",
        "          0 <= x_i <= 1  for all i\n",
        "\n",
        "where:\n",
        "    H = 2*alpha*I + 2*K   (made symmetric)\n",
        "    ff = (beta/2) * all_distances - 2 * K[:, j]\n",
        "    all_distances[i] = || F[j,:] - F[i,:] ||^2\n",
        "\n",
        "Notes:\n",
        " - This implementation uses scipy.optimize.minimize (SLSQP) as a generic QP solver.\n",
        " - For better performance on large n, prefer a specialized QP solver (cvxopt, quadprog, OSQP).\n",
        " - Returns Z as an (n, n) numpy array where column j is the solution for column j.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from typing import Optional\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def UpdateS(K: np.ndarray, F: np.ndarray, alpha: float, beta: float,\n",
        "             tol: float = 1e-8, verbose: bool = False) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute matrix Z by solving n QPs, one for each column.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    K : (n, n) array-like\n",
        "        Kernel / similarity matrix used in the quadratic cost.\n",
        "    F : (n, d) array-like\n",
        "        Feature (embedding) matrix. Each row F[i,:] is the feature vector for sample i.\n",
        "    alpha : float\n",
        "        Parameter as in the paper.\n",
        "    beta : float\n",
        "        Parameter as in the paper.\n",
        "    tol : float\n",
        "        Tolerance for solver termination (passed to minimize).\n",
        "    verbose : bool\n",
        "        If True, prints progress information.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Z : (n, n) np.ndarray\n",
        "        Each column j is the solution vector for the j-th QP.\n",
        "    \"\"\"\n",
        "\n",
        "    K = np.asarray(K, dtype=float)\n",
        "    F = np.asarray(F, dtype=float)\n",
        "    if K.ndim != 2 or K.shape[0] != K.shape[1]:\n",
        "        raise ValueError(\"K must be a square matrix (n x n).\")\n",
        "    n = K.shape[0]\n",
        "    if F.shape[0] != n:\n",
        "        raise ValueError(\"F must have the same number of rows as K (n).\")\n",
        "\n",
        "    # Precompute H = 2*alpha*I + 2*K (ensure symmetric)\n",
        "    H = 2.0 * alpha * np.eye(n) + 2.0 * K\n",
        "    H = 0.5 * (H + H.T)   # symmetrize to reduce numerical issues\n",
        "\n",
        "    # Precompute pairwise squared norms of F rows maybe helpful for speed\n",
        "    # But we only need ||F[j] - F[i]||^2 for each j; compute per j below vectorized.\n",
        "\n",
        "    Z = np.zeros((n, n), dtype=float)\n",
        "\n",
        "    # constraints: equality sum(x) = 1 and bounds 0<=x<=1\n",
        "    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0,\n",
        "             'jac': lambda x: np.ones_like(x)})\n",
        "    bounds = [(0.0, 1.0) for _ in range(n)]\n",
        "\n",
        "    # Pre-factor: for faster gradient calc we can reuse H\n",
        "    # Objective function and gradient for a given ff:\n",
        "    def _objective(x, H_mat, ff_vec):\n",
        "        # 0.5 x^T H x + ff^T x\n",
        "        # grad = H x + ff\n",
        "        x = np.asarray(x)\n",
        "        obj = 0.5 * x.dot(H_mat.dot(x)) + ff_vec.dot(x)\n",
        "        grad = H_mat.dot(x) + ff_vec\n",
        "        return obj, grad\n",
        "\n",
        "    # Use uniform initial guess\n",
        "    x0 = np.full(n, 1.0 / n)\n",
        "\n",
        "    for j in range(n):\n",
        "        # compute all squared distances between F[j,:] and every row F[i,:]\n",
        "        # vectorized: (F - F[j])**2 sum over columns\n",
        "        diff = F - F[j, :]  # shape (n, d)\n",
        "        all_sq = np.sum(diff * diff, axis=1)  # shape (n,)\n",
        "\n",
        "        # ff = beta/2 * all' - 2*K(:,j)\n",
        "        ff = (beta / 2.0) * all_sq - 2.0 * K[:, j]\n",
        "\n",
        "        # objective wrapper for scipy.minimize (SLSQP accepts jac)\n",
        "        def obj_for_min(x):\n",
        "            val, grad = _objective(x, H, ff)\n",
        "            return val, grad\n",
        "\n",
        "        # SciPy minimize expects separate functions for fun and jac OR return both with method='SLSQP'\n",
        "        def fun(x):\n",
        "            val, _ = _objective(x, H, ff)\n",
        "            return val\n",
        "\n",
        "        def jac(x):\n",
        "            _, grad = _objective(x, H, ff)\n",
        "            return grad\n",
        "\n",
        "        # run SLSQP\n",
        "        res = minimize(fun, x0, method='SLSQP', jac=jac,\n",
        "                       bounds=bounds, constraints=cons,\n",
        "                       options={'ftol': tol, 'maxiter': 1000, 'disp': False})\n",
        "\n",
        "        if not res.success:\n",
        "            # If SLSQP failed to converge, we can try a fallback: more iterations or different init\n",
        "            # Try a different initial point (e.g., projection of -ff onto simplex)\n",
        "            if verbose:\n",
        "                print(f\"Warning: solver failed at column {j}, message: {res.message}. Trying fallback init.\")\n",
        "            # fallback init: project uniform+small random noise\n",
        "            x0_fallback = np.clip(x0 + 1e-3 * np.random.randn(n), 0, 1)\n",
        "            x0_fallback = x0_fallback / np.sum(x0_fallback)\n",
        "            res2 = minimize(fun, x0_fallback, method='SLSQP', jac=jac,\n",
        "                            bounds=bounds, constraints=cons,\n",
        "                            options={'ftol': tol, 'maxiter': 2000, 'disp': False})\n",
        "            if res2.success:\n",
        "                sol = res2.x\n",
        "            else:\n",
        "                # last resort: project the unconstrained quadratic minimizer on simplex then clip\n",
        "                # unconstrained solution x* = -H^{-1} ff\n",
        "                try:\n",
        "                    sol_unc = -np.linalg.solve(H, ff)\n",
        "                except np.linalg.LinAlgError:\n",
        "                    sol_unc = -np.linalg.pinv(H).dot(ff)\n",
        "                # project onto simplex\n",
        "                sol_proj = _project_to_simplex(sol_unc)\n",
        "                # clip to [0,1]\n",
        "                sol = np.clip(sol_proj, 0.0, 1.0)\n",
        "                sol = sol / np.sum(sol)  # re-normalize to sum to 1\n",
        "        else:\n",
        "            sol = res.x\n",
        "\n",
        "        Z[:, j] = sol\n",
        "        # next initial guess = current solution (warm start)\n",
        "        x0 = sol\n",
        "\n",
        "    return Z\n",
        "\n",
        "# helper: projection to simplex (useful fallback)\n",
        "def _project_to_simplex(v: np.ndarray, z: float = 1.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Euclidean projection of v onto the probability simplex { x : x >= 0, sum(x) = z }.\n",
        "    Reference: Efficient Projections onto the L1-Ball for Learning in High Dimensions,\n",
        "               John Duchi et al. (2008).\n",
        "    \"\"\"\n",
        "    v = np.asarray(v, dtype=float).copy()\n",
        "    n = v.size\n",
        "    if np.sum(v) == z and np.all(v >= 0):\n",
        "        return v\n",
        "    u = np.sort(v)[::-1]\n",
        "    cssv = np.cumsum(u)\n",
        "    rho = np.where(u * np.arange(1, n+1) > (cssv - z))[0]\n",
        "    if rho.size == 0:\n",
        "        theta = 0.0\n",
        "    else:\n",
        "        rho = rho[-1]\n",
        "        theta = (cssv[rho] - z) / float(rho + 1)\n",
        "    w = np.maximum(v - theta, 0.0)\n",
        "    return w\n",
        "\n",
        "# Optional: fast solver hint using cvxopt (commented)\n",
        "# If you have cvxopt installed and prefer to use it, you can replace the SLSQP call by cvxopt.solvers.qp.\n",
        "# Example (not active in this code):\n",
        "#\n",
        "# from cvxopt import matrix, solvers\n",
        "# P = matrix(H)\n",
        "# q = matrix(ff)\n",
        "# # equality: A x = b  -> sum x = 1\n",
        "# A = matrix(np.ones((1,n)))\n",
        "# b = matrix(1.0)\n",
        "# # bounds: 0 <= x <= 1  -> Gx <= h\n",
        "# G = matrix(np.vstack((-np.eye(n), np.eye(n))))\n",
        "# h = matrix(np.hstack((np.zeros(n), np.ones(n))))\n",
        "# sol = solvers.qp(P, q, G, h, A, b)\n",
        "# if sol['status'] == 'optimal':\n",
        "#     sol_x = np.array(sol['x']).ravel()\n",
        "# else:\n",
        "#     handle_failure...\n",
        "#\n",
        "# cvxopt is usually faster and more stable for dense QPs than SLSQP for large n.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5qD1M-SoExk",
        "outputId": "6b176e88-4280-42d3-f45a-dab9aef9481a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting UpdateS.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile UpdateW.py\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "update_P.py\n",
        "\n",
        "Port of MATLAB UpdateP.m / UpdateW.m to Python (NumPy).\n",
        "\n",
        "Function:\n",
        "    D_mat = update_P(Coef, Data, D_mat_init, tol=1e-6, max_iter=100, rho_init=1.0, rate_rho=1.2)\n",
        "\n",
        "Inputs:\n",
        "    Coef         : numpy array (d, N)  -- corresponds to 'Coef' (H in your comment)\n",
        "    Data         : numpy array (m, N)  -- corresponds to 'Data' (M in your comment)\n",
        "    D_mat_init   : numpy array (m, d)  -- initial W (previous D_Mat)\n",
        "    tol          : float, stopping threshold on mean squared change (default 1e-6)\n",
        "    max_iter     : int, maximum iterations (default 100)\n",
        "    rho_init     : float, initial rho (default 1.0)\n",
        "    rate_rho     : float, multiplier to increase rho each iteration (default 1.2)\n",
        "\n",
        "Returns:\n",
        "    D_mat : numpy array (m, d) -- updated mapping W (TempD)\n",
        "\n",
        "Notes:\n",
        "    - This implements the same iteration as the MATLAB code:\n",
        "        TempD   = (rho*(TempS-TempT) + TempData*TempCoef') * inv(rho*I + TempCoef*TempCoef')\n",
        "        TempS   = normcol_lessequal(TempD + TempT)\n",
        "        TempT   = TempT + TempD - TempS\n",
        "    - normcol_lessequal scales each column to have L2 norm <= 1 (i.e., unit ball projection).\n",
        "    - Uses np.linalg.solve (via transposed system) instead of explicit inverse for numerical stability.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _normcol_lessequal(X: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Project each column of X to have l2-norm <= 1.\n",
        "    If a column's norm > 1, scale it to have norm 1; otherwise keep it unchanged.\n",
        "    \"\"\"\n",
        "    X = np.asarray(X, dtype=float)\n",
        "    norms = np.linalg.norm(X, axis=0)\n",
        "    # avoid division by zero\n",
        "    scale = np.ones_like(norms)\n",
        "    mask = norms > 1.0\n",
        "    if np.any(mask):\n",
        "        scale[mask] = 1.0 / norms[mask]\n",
        "    # multiply each column by corresponding scalar\n",
        "    return X * scale\n",
        "\n",
        "def UpdateW(Coef: np.ndarray, Data: np.ndarray, D_mat_init: np.ndarray,\n",
        "             tol: float = 1e-6, max_iter: int = 100,\n",
        "             rho_init: float = 1.0, rate_rho: float = 1.2) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    ADMM-style update for D (W) as in UpdateP/UpdateW.m\n",
        "    \"\"\"\n",
        "    Coef = np.asarray(Coef, dtype=float)   # shape (d, N)\n",
        "    Data = np.asarray(Data, dtype=float)   # shape (m, N)\n",
        "    TempS = np.asarray(D_mat_init, dtype=float)  # shape (m, d)\n",
        "\n",
        "    d = Coef.shape[0]  # number of rows of Coef (dimension d)\n",
        "    # Validate shapes:\n",
        "    if Coef.ndim != 2:\n",
        "        raise ValueError(\"Coef must be 2D (d x N).\")\n",
        "    if Data.ndim != 2:\n",
        "        raise ValueError(\"Data must be 2D (m x N).\")\n",
        "    if TempS.ndim != 2:\n",
        "        raise ValueError(\"D_mat_init must be 2D (m x d).\")\n",
        "    if TempS.shape[1] != d:\n",
        "        raise ValueError(\"D_mat_init must have number of columns equal to number of rows of Coef (d).\")\n",
        "    if Data.shape[1] != Coef.shape[1]:\n",
        "        raise ValueError(\"Data and Coef must have the same number of columns (N).\")\n",
        "\n",
        "    m = Data.shape[0]  # output dimension\n",
        "    # initialize variables\n",
        "    TempT = np.zeros_like(TempS)   # Lagrange multiplier-like variable\n",
        "    previousD = TempS.copy()\n",
        "    rho = float(rho_init)\n",
        "    Imat = np.eye(d)\n",
        "\n",
        "    Iter = 1\n",
        "    ERROR = 1.0\n",
        "\n",
        "    # Precompute TempCoef * TempCoef' structure: note it changes not in loop\n",
        "    # But TempCoef is constant (Coef). So denom = rho*I + Coef @ Coef.T (d x d)\n",
        "    # However rho changes each iteration, so precompute Coef @ Coef.T once and reuse.\n",
        "    CoefCoefT = Coef @ Coef.T  # shape (d, d)\n",
        "\n",
        "    while ERROR > tol and Iter < max_iter:\n",
        "        # numerator: rho*(TempS - TempT) + Data * Coef'\n",
        "        numerator = rho * (TempS - TempT) + (Data @ Coef.T)  # shape (m, d)\n",
        "\n",
        "        # denom: rho*I + Coef*Coef'\n",
        "        denom = rho * Imat + CoefCoefT  # shape (d, d)\n",
        "        # Solve for TempD: TempD = numerator * inv(denom)\n",
        "        # To avoid explicit inverse, we solve: denom^T * X^T = numerator^T  => X = (solve(denom.T, numerator.T)).T\n",
        "        # This yields TempD of shape (m, d)\n",
        "        try:\n",
        "            TempD = np.linalg.solve(denom.T, numerator.T).T\n",
        "        except np.linalg.LinAlgError:\n",
        "            # fallback to pseudo-inverse if denom is singular\n",
        "            denom_inv = np.linalg.pinv(denom)\n",
        "            TempD = numerator @ denom_inv\n",
        "\n",
        "        # Update TempS by projecting columns of (TempD + TempT) to have norm <= 1\n",
        "        TempS = _normcol_lessequal(TempD + TempT)\n",
        "\n",
        "        # Update TempT\n",
        "        TempT = TempT + TempD - TempS\n",
        "\n",
        "        # update rho\n",
        "        rho = rate_rho * rho\n",
        "\n",
        "        # compute stopping criterion (mean squared change)\n",
        "        ERROR = np.mean((previousD - TempD) ** 2)\n",
        "        previousD = TempD.copy()\n",
        "        Iter += 1\n",
        "\n",
        "    D_mat = TempD\n",
        "    return D_mat\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED5Z3IBQoZsz",
        "outputId": "63b81f94-e738-454a-85cf-3acc622fc59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting UpdateW.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile SMR_mtv.py\n",
        "\n",
        "\"\"\"\n",
        "smr_mtv.py\n",
        "\n",
        "Port of MATLAB function SMR_mtv (SMR.m) to Python.\n",
        "\n",
        "Solves the Sylvester equation used in the paper:\n",
        "    A_syl * H + H * B_syl + C_syl = 0\n",
        "\n",
        "MATLAB call:\n",
        "    H = lyap(A_syl, B_syl, C_syl)\n",
        "\n",
        "We use scipy.linalg.solve_sylvester which solves:\n",
        "    A * X + X * B = C\n",
        "\n",
        "So to match MATLAB's lyap we set C_scipy = -C_syl.\n",
        "\n",
        "Function:\n",
        "    H = SMR_mtv(M, P, S, alpha)\n",
        "\n",
        "Inputs:\n",
        "    M     : (m, N) numpy array\n",
        "    P     : (N, c) numpy array  (cluster indicator matrix)\n",
        "    S     : (N, N) numpy array  (similarity matrix)\n",
        "    alpha : scalar\n",
        "\n",
        "Output:\n",
        "    H     : (c, N) numpy array  (solution of the Sylvester equation)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from scipy.linalg import solve_sylvester\n",
        "from typing import Any\n",
        "\n",
        "def SMR_mtv(M: np.ndarray, P: np.ndarray, S: np.ndarray, alpha: float) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Solve for H such that A_syl * H + H * B_syl + C_syl = 0 where:\n",
        "        A_syl = P.T @ P        (c x c)\n",
        "        B_syl = alpha*(I - S) @ (I - S).T   (N x N)\n",
        "        C_syl = - P.T @ M      (c x N)\n",
        "\n",
        "    Returns H (c x N).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    M : array_like, shape (m, N)\n",
        "    P : array_like, shape (N, c)\n",
        "    S : array_like, shape (N, N)\n",
        "    alpha : float\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    H : ndarray, shape (c, N)\n",
        "    \"\"\"\n",
        "    M = np.asarray(M, dtype=float)\n",
        "    P = np.asarray(P, dtype=float)\n",
        "    S = np.asarray(S, dtype=float)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    # Basic validation\n",
        "    if S.ndim != 2 or S.shape[0] != S.shape[1]:\n",
        "        raise ValueError(\"S must be a square matrix (N x N).\")\n",
        "    N = S.shape[0]\n",
        "\n",
        "    if P.ndim != 2 or P.shape[0] != N:\n",
        "        raise ValueError(\"P must have shape (N, c) with the same N as S.\")\n",
        "    if M.ndim != 2 or M.shape[1] != N:\n",
        "        raise ValueError(\"M must have shape (m, N) with same N as S and P.\")\n",
        "\n",
        "    # Build matrices for Sylvester equation\n",
        "    A_syl = P.T @ P  # shape (c, c)\n",
        "    I = np.eye(N)\n",
        "    diff = I - S\n",
        "    B_syl = alpha * (diff @ diff.T)  # shape (N, N)\n",
        "    # In MATLAB: C_syl = -P'*M ; lyap solves A*X + X*B + C = 0\n",
        "    # scipy.linalg.solve_sylvester solves A*X + X*B = C.\n",
        "    # Thus we set C_scipy = -C_syl = P' * M\n",
        "    C_scipy = P.T @ M  # shape (c, N)\n",
        "\n",
        "    # Solve A_syl * H + H * B_syl = C_scipy\n",
        "    H = solve_sylvester(A_syl, B_syl, C_scipy)\n",
        "\n",
        "    return H\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR8XjWVXpuXi",
        "outputId": "353bd2f1-ed7d-4b3f-ec6a-d95b9079de2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting SMR_mtv.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile normcol_lessequal.py\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "normcol_lessequal.py\n",
        "\n",
        "Port of MATLAB function normcol_lessequal.m to Python (NumPy).\n",
        "\n",
        "Behavior:\n",
        "    matout = argmin ||matout - matin||_F^2  subject to each column norm(matout[:, i]) <= 1\n",
        "\n",
        "Usage:\n",
        "    matout = normcol_lessequal(matin)\n",
        "\n",
        "Inputs:\n",
        "    matin : (m, n) array-like\n",
        "\n",
        "Returns:\n",
        "    matout : (m, n) ndarray with each column scaled to have l2-norm <= 1\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def normcol_lessequal(matin: np.ndarray) -> np.ndarray:\n",
        "    matin = np.asarray(matin, dtype=float)\n",
        "    # compute l2 norms of columns\n",
        "    # sum over rows (axis=0), keepdims for broadcasting\n",
        "    eps = np.finfo(float).eps\n",
        "    col_norms = np.sqrt(np.sum(matin * matin, axis=0) + eps)  # shape (n,)\n",
        "    # denom = max(1, col_norm) per column\n",
        "    denom = np.maximum(1.0, col_norms)\n",
        "    # scale columns: matin / denom (broadcast denom over rows)\n",
        "    matout = matin / denom[np.newaxis, :]\n",
        "    return matout\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SRVrJPVqAdz",
        "outputId": "5cab50ae-7992-4be1-f57e-7522ef86ace6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting normcol_lessequal.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile MCLES.py\n",
        "\n",
        "\n",
        "\n",
        "from UpdateS import UpdateS\n",
        "from UpdateW import UpdateW\n",
        "from eig1 import eig1\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "MCLES.py\n",
        "\n",
        "Python port of MCLES.m (Multi-View Clustering in Latent Embedding Space).\n",
        "\n",
        "Dependencies:\n",
        "    numpy, scipy, scikit-learn\n",
        "\n",
        "Assumed helper functions (place in same folder or importable):\n",
        "    - update_P(Coef, Data, D_mat_init, ...)      # corresponds to UpdateP.m (UpdateW)\n",
        "    - update_S(K, F, alpha, beta, ...)           # corresponds to UpdateS.m\n",
        "    - eig1(A, c=None, isMax=True, isSym=True)    # corresponds to eig1.m\n",
        "\n",
        "This file implements the top-level MCLES() function and clustering metrics.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from scipy.linalg import solve_sylvester  # for Sylvester equation\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from typing import List, Tuple\n",
        "\n",
        "# If you placed your converted helper functions in other files, import them:\n",
        "# from update_p import update_P\n",
        "# from update_s import update_S\n",
        "# from eig1 import eig1\n",
        "\n",
        "# If you haven't yet converted them to python files, you can place them as functions\n",
        "# in this module or update the import paths above.\n",
        "\n",
        "def clustering_measure(true_labels: np.ndarray, pred_labels: np.ndarray\n",
        "                       ) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Compute ACC (accuracy via optimal assignment), NMI, PUR (purity).\n",
        "    true_labels : array-like shape (N,)\n",
        "    pred_labels : array-like shape (N,)\n",
        "    Returns (ACC, NMI, PUR)\n",
        "    \"\"\"\n",
        "    true = np.asarray(true_labels).astype(int)\n",
        "    pred = np.asarray(pred_labels).astype(int)\n",
        "    N = true.size\n",
        "\n",
        "    # NMI\n",
        "    nmi = normalized_mutual_info_score(true, pred)\n",
        "\n",
        "    # ACC via Hungarian on the contingency matrix\n",
        "    # Build contingency matrix\n",
        "    labels_true = np.unique(true)\n",
        "    labels_pred = np.unique(pred)\n",
        "    # Map labels to [0..k-1]\n",
        "    true_map = {lab: i for i, lab in enumerate(labels_true)}\n",
        "    pred_map = {lab: i for i, lab in enumerate(labels_pred)}\n",
        "    K_true = labels_true.size\n",
        "    K_pred = labels_pred.size\n",
        "    cont = np.zeros((K_true, K_pred), dtype=np.int64)\n",
        "    for t, p in zip(true, pred):\n",
        "        cont[true_map[t], pred_map[p]] += 1\n",
        "    # Hungarian to maximize matching -> minimize -cont\n",
        "    row_ind, col_ind = linear_sum_assignment(-cont)\n",
        "    acc = cont[row_ind, col_ind].sum() / N\n",
        "\n",
        "    # Purity: sum of max intersection per predicted cluster divided by N\n",
        "    # For each predicted cluster, find the max true label count\n",
        "    pur = 0\n",
        "    for j, pj in enumerate(labels_pred):\n",
        "        idx = (pred == pj)\n",
        "        if idx.sum() == 0:\n",
        "            continue\n",
        "        # get true labels of these points\n",
        "        counts = np.bincount(true[idx])\n",
        "        pur += counts.max()\n",
        "    purity = pur / N\n",
        "\n",
        "    return acc, nmi, purity\n",
        "\n",
        "\n",
        "def _solve_sylvester_for_H(M: np.ndarray, P_mat: np.ndarray, S: np.ndarray, alpha: float) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Solve Sylvester equation A*H + H*B + C = 0 for H, where:\n",
        "        A = P_mat.T @ P_mat\n",
        "        B = alpha * (I - S) @ (I - S).T\n",
        "        C = - P_mat.T @ M\n",
        "\n",
        "    scipy.linalg.solve_sylvester solves A*X + X*B = C_scipy,\n",
        "    so we set C_scipy = -C = P_mat.T @ M.\n",
        "\n",
        "    Note: P_mat must have same number of rows as M (both are m x ...),\n",
        "    so that P_mat.T @ M has shape (d, N), yielding H shape (d, N).\n",
        "    \"\"\"\n",
        "    # input validation\n",
        "    M = np.asarray(M, dtype=float)\n",
        "    P_mat = np.asarray(P_mat, dtype=float)\n",
        "    S = np.asarray(S, dtype=float)\n",
        "    N = S.shape[0]\n",
        "    if M.ndim != 2 or M.shape[1] != N:\n",
        "        raise ValueError(\"M must have shape (m, N) where N = number of samples (S.shape[0])\")\n",
        "    if P_mat.shape[0] != M.shape[0]:\n",
        "        raise ValueError(\"P (W) must have the same number of rows as M (both are 'm' rows).\")\n",
        "\n",
        "    A_syl = P_mat.T @ P_mat  # (d x d)\n",
        "    I = np.eye(N)\n",
        "    diff = I - S\n",
        "    B_syl = alpha * (diff @ diff.T)  # (N x N)\n",
        "    C_scipy = P_mat.T @ M  # (d x N)\n",
        "\n",
        "    H = solve_sylvester(A_syl, B_syl, C_scipy)  # solves A H + H B = C_scipy\n",
        "    # The MATLAB lyap(A,B,C) used C = -P'*M and solved A*H + H*B + C = 0\n",
        "    # which is equivalent to A H + H B = P' M  (exactly what we solved).\n",
        "    return H\n",
        "\n",
        "\n",
        "def MCLES(X: List[np.ndarray], alpha: float, beta: float, d: int, gamma: float,\n",
        "          maxIters: int, gt: np.ndarray, verbose: bool = False\n",
        "         ) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Main MCLES function translated from MCLES.m\n",
        "\n",
        "    Inputs:\n",
        "      X        : list of V views, each view is a numpy array of shape (d_v, N)\n",
        "      alpha,beta,gamma: parameters (scalars)\n",
        "      d        : embedding dimension (int)\n",
        "      maxIters : maximum outer iterations (int)\n",
        "      gt       : ground-truth labels, array shape (N,)\n",
        "\n",
        "    Returns:\n",
        "      result : numpy array [ACC, NMI, PUR]\n",
        "    \"\"\"\n",
        "    # number of classes\n",
        "    gt = np.asarray(gt)\n",
        "    C = np.unique(gt).size\n",
        "    V = len(X)\n",
        "    N = X[0].shape[1]\n",
        "\n",
        "    # normalize each view (column-wise)\n",
        "    X_normed = []\n",
        "    for v in range(V):\n",
        "        Xi = np.asarray(X[v], dtype=float)\n",
        "        # column norms\n",
        "        col_norms = np.sqrt(np.sum(Xi ** 2, axis=0) + np.finfo(float).eps)\n",
        "        Xi = Xi / (col_norms[np.newaxis, :])\n",
        "        X_normed.append(Xi)\n",
        "\n",
        "    # dimensions and construct M (vertical concatenation)\n",
        "    Ds = [Xi.shape[0] for Xi in X_normed]\n",
        "    SD = sum(Ds)\n",
        "    M = np.vstack(X_normed)   # shape (SD, N)\n",
        "\n",
        "    # initialize variables\n",
        "    W = np.zeros((SD, d), dtype=float)      # W (m x d)\n",
        "    H = np.random.randn(d, N)               # H (d x N)\n",
        "    S = np.zeros((N, N), dtype=float)       # similarity matrix\n",
        "    F = np.random.randn(N, C)               # F used in UpdateS distances (N x C)\n",
        "\n",
        "    # parameters for KMeans\n",
        "    MAXiter = 1000\n",
        "    REPlic = 20\n",
        "\n",
        "    Obj = []\n",
        "    for it in range(maxIters):\n",
        "        if verbose:\n",
        "            print(f\"[MCLES] Iter {it+1}/{maxIters}\")\n",
        "\n",
        "        # ------ update W (UpdateW / UpdateP) ------\n",
        "        # update_P expects: Coef (d x N), Data (m x N), D_mat_init (m x d)\n",
        "        # In MATLAB: W = UpdateW(H,M,W)\n",
        "        # So call update_P(H, M, W)\n",
        "        # NOTE: ensure you have converted UpdateP to update_P and it's importable.\n",
        "        try:\n",
        "            # user-provided conversion for UpdateP.m\n",
        "            W = UpdateW(H, M, W)\n",
        "        except Exception as e:\n",
        "            # If update_p is not available, raise clear error\n",
        "            raise ImportError(\"UpdateW (converted from UpdateP.m) not found or failed. \"\n",
        "                              \"Please place UpdateW in module UpdateW.py. \"\n",
        "                              f\"Original error: {e}\")\n",
        "\n",
        "        # ------ update H (SMR_mtv) ------\n",
        "        # In MATLAB: H = SMR_mtv(M,W,S,alpha);\n",
        "        # We provide a local Sylvester solver to compute H:\n",
        "        H = _solve_sylvester_for_H(M, W, S, alpha)  # returns (d, N)\n",
        "\n",
        "        # ------ update S ------\n",
        "        # In MATLAB: S = UpdateS(H'*H,F,beta/alpha,gamma/alpha);\n",
        "        K = H.T @ H   # shape (N, N)\n",
        "        try:\n",
        "             # user-provided conversion for UpdateS.m\n",
        "            S = UpdateS(K, F, beta / alpha, gamma / alpha)\n",
        "        except Exception as e:\n",
        "            raise ImportError(\"UpdateS (converted from UpdateS.m) not found or failed. \"\n",
        "                              \"Please place UpdateS in module UpdateS.py. \"\n",
        "                              f\"Original error: {e}\")\n",
        "\n",
        "        # ------ update F (spectral embedding from Laplacian) ------\n",
        "        Z = S\n",
        "        Z = 0.5 * (Z + Z.T)\n",
        "        D_diag = np.sum(Z, axis=1)\n",
        "        D_mat = np.diag(D_diag)\n",
        "        L = D_mat - Z\n",
        "        # eig1: eigvec, eigval, eigval_full = eig1(A, c=None, isMax=True, isSym=True)\n",
        "        try:\n",
        "\n",
        "            F_new, _, _ = eig1(L, C, isMax=False, isSym=True)\n",
        "        except Exception as e:\n",
        "            raise ImportError(\"eig1 (converted from eig1.m) not found or failed. \"\n",
        "                              \"Please place eig1 in module eig1.py. \"\n",
        "                              f\"Original error: {e}\")\n",
        "\n",
        "        # eig1 returns eigenvectors as columns (N x C)\n",
        "        F = np.asarray(F_new, dtype=float)\n",
        "\n",
        "        # ------ compute objective ------\n",
        "        term1 = np.linalg.norm(M - W @ H, ord='fro') ** 2\n",
        "        term2 = alpha * (np.linalg.norm(H - H @ S, ord='fro') ** 2)\n",
        "        term3 = beta * (np.linalg.norm(S, ord='fro') ** 2)\n",
        "        term4 = gamma * np.trace(F.T @ L @ F)\n",
        "        obj_val = term1 + term2 + term3 + term4\n",
        "        Obj.append(obj_val)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  Obj = {obj_val:.6e} (terms: {term1:.3e}, {term2:.3e}, {term3:.3e}, {term4:.3e})\")\n",
        "\n",
        "        # convergence check (relative change < 1e-2)\n",
        "        if it > 0:\n",
        "            rel_change = abs(Obj[-1] - Obj[-2]) / (abs(Obj[-2]) + 1e-12)\n",
        "            if rel_change < 1e-2:\n",
        "                if verbose:\n",
        "                    print(f\"[MCLES] Converged at iteration {it+1}, rel_change={rel_change:.4e}\")\n",
        "                break\n",
        "\n",
        "    # final kmeans on F (rows are samples -> sklearn expects shape (n_samples, n_features))\n",
        "    kmeans = KMeans(n_clusters=C, n_init=REPlic, max_iter=MAXiter, random_state=0)\n",
        "    labels = kmeans.fit_predict(F)  # shape (N,)\n",
        "\n",
        "    ACC, NMI, PUR = clustering_measure(gt, labels)\n",
        "    result = np.array([ACC, NMI, PUR], dtype=float)\n",
        "    return result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dneXB59qSTw",
        "outputId": "76555ebe-999e-4907-a946-37f0770a06ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting MCLES.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from MCLES import MCLES\n",
        "\n",
        "\"\"\"\n",
        "Python port of run.m for MSRC-v1 experiment.\n",
        "\n",
        "This script:\n",
        "- loads MSRC-v1.mat (expects variables X and Y or similar),\n",
        "- converts views to shape (d_v, N) as expected by MCLES,\n",
        "- sets MCLES parameters,\n",
        "- runs MCLES and prints the resulting [ACC, NMI, PUR].\n",
        "\n",
        "Usage:\n",
        "    python run_mccles.py\n",
        "\n",
        "Make sure:\n",
        "- MSRC-v1.mat is in the same directory or give full path to it.\n",
        "- mccles.py and helper modules (update_p.py, update_s.py, eig1.py, etc.) are importable.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# import your converted MCLES function\n",
        "# from mccles import MCLES\n",
        "\n",
        "def load_mat_views(mat_path: str):\n",
        "    \"\"\"\n",
        "    Load a .mat file and extract X (list of views) and Y (ground-truth labels).\n",
        "    This function tries a few common layouts produced by MATLAB .mat files.\n",
        "\n",
        "    Returns:\n",
        "        X_views: list of numpy arrays, each array shape (d_v, N)  -- matches expected MCLES input.\n",
        "        Y: 1D numpy array of length N (integers)\n",
        "    \"\"\"\n",
        "    data = loadmat(mat_path)\n",
        "    # Try common keys\n",
        "    if 'X' in data:\n",
        "        X_mat = data['X']\n",
        "        # MATLAB cell arrays are loaded as numpy object arrays by scipy.io.loadmat\n",
        "        if isinstance(X_mat, np.ndarray) and X_mat.dtype == np.object_:\n",
        "            # Flatten object array and extract arrays\n",
        "            X_list = [np.asarray(v) for v in X_mat.flatten()]\n",
        "        else:\n",
        "            # If X is a numeric array, try to interpret: maybe shape (V, ...) or (d, N, V)\n",
        "            # Try to detect 3D arrays with last dimension as views\n",
        "            if X_mat.ndim == 3:\n",
        "                # ph: (d, N, V) -> extract along third axis\n",
        "                V = X_mat.shape[2]\n",
        "                X_list = [X_mat[:, :, i] for i in range(V)]\n",
        "            else:\n",
        "                # fallback: wrap single view\n",
        "                X_list = [np.asarray(X_mat)]\n",
        "    else:\n",
        "        # fallback keys some datasets use (try to detect feature sets)\n",
        "        # e.g., 'gist', 'hog', 'lbp', 'sift' etc.\n",
        "        candidates = ['gist', 'hog', 'lbp', 'SIFT', 'X']  # extend as needed\n",
        "        X_list = []\n",
        "        for k in candidates:\n",
        "            if k in data:\n",
        "                X_list.append(np.asarray(data[k]))\n",
        "        if len(X_list) == 0:\n",
        "            raise KeyError(\"Cannot find 'X' or known feature keys in the .mat file.\")\n",
        "\n",
        "    # Get ground truth labels\n",
        "    if 'Y' in data:\n",
        "        Y = np.asarray(data['Y']).squeeze()\n",
        "    elif 'y' in data:\n",
        "        Y = np.asarray(data['gt']).squeeze()\n",
        "    elif 'labels' in data:\n",
        "        Y = np.asarray(data['labels']).squeeze()\n",
        "    else:\n",
        "        # last resort: try to find a 1D integer array among variables\n",
        "        possible = []\n",
        "        for k, v in data.items():\n",
        "            if k.startswith('__'):\n",
        "                continue\n",
        "            arr = np.asarray(v)\n",
        "            if arr.ndim == 2 and 1 in arr.shape and arr.size > 0:\n",
        "                possible.append((k, arr.squeeze()))\n",
        "        if len(possible) >= 1:\n",
        "            # pick the first candidate (this is a last-resort heuristic)\n",
        "            print(\"Warning: ground truth not found with key 'Y'/'gt'. Using variable:\", possible[0][0])\n",
        "            Y = possible[0][1]\n",
        "        else:\n",
        "            raise KeyError(\"Ground-truth labels not found in the .mat file (keys tried: Y, gt, labels).\")\n",
        "\n",
        "    # MATLAB often stores each view as (dv x N) or (N x dv). In your run.m you transposed each view:\n",
        "    #    temp = X{i}; X{i} = temp';\n",
        "    # That suggests loaded X{i} was (dv, N?) and they wanted (N features?) However earlier code expects X{i} to be (dv, N) .\n",
        "    # To match your earlier conversions we will follow the same step: transpose each view if its second dimension mismatches N.\n",
        "    # Determine N by checking the length of Y.\n",
        "    Y = np.asarray(Y)\n",
        "    N = Y.size\n",
        "\n",
        "    X_views = []\n",
        "    for v_arr in X_list:\n",
        "        arr = np.asarray(v_arr)\n",
        "        # If arr shape is (N, d_v), transpose to (d_v, N)\n",
        "        if arr.ndim == 2 and arr.shape[0] == N and arr.shape[1] != N:\n",
        "            arr = arr.T\n",
        "        # If arr shape is (d_v, N) already, keep\n",
        "        # If ambiguous (square), leave as-is\n",
        "        X_views.append(arr)\n",
        "\n",
        "    # Verify consistent N across views\n",
        "    for i, arr in enumerate(X_views):\n",
        "        if arr.ndim != 2:\n",
        "            raise ValueError(f\"View {i} is not 2D array.\")\n",
        "        if arr.shape[1] != N:\n",
        "            raise ValueError(f\"View {i} has inconsistent number of samples: expected {N}, got {arr.shape[1]}\")\n",
        "\n",
        "    return X_views, Y\n",
        "\n",
        "def main():\n",
        "    # Path to the .mat file (adjust if needed)\n",
        "    mat_file = 'MSRC-v1.mat'\n",
        "    if not os.path.exists(mat_file):\n",
        "        raise FileNotFoundError(f\"{mat_file} not found in current directory ({os.getcwd()}). Place the file here or update the path.\")\n",
        "\n",
        "    # load views and labels\n",
        "    X_views, gt = load_mat_views(mat_file)\n",
        "    print(f\"Loaded {len(X_views)} views, N = {gt.size}\")\n",
        "\n",
        "    # MCLES parameters (same as your run.m)\n",
        "    maxIters = 30\n",
        "    alpha = 0.8\n",
        "    beta = 0.4\n",
        "    d = 70\n",
        "    gamma = 0.004\n",
        "\n",
        "    # Run MCLES\n",
        "    result = MCLES(X_views, alpha, beta, d, gamma, maxIters, gt, verbose=True)\n",
        "    print(\"Result [ACC, NMI, PUR] =\", result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RDVzI_Yqkfp",
        "outputId": "bae8aedd-c925-4dbc-87ce-942dd2051319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nts-9XNnvfZt",
        "outputId": "0c3083bb-fc1b-4436-a42e-5545a274f240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 4 views, N = 210\n",
            "[MCLES] Iter 1/30\n",
            "  Obj = 1.351639e+02 (terms: 1.330e+02, 6.885e-01, 1.420e+00, 1.081e-02)\n",
            "[MCLES] Iter 2/30\n",
            "  Obj = 3.174836e+01 (terms: 2.740e+01, 2.680e+00, 1.658e+00, 1.197e-02)\n",
            "[MCLES] Iter 3/30\n",
            "  Obj = 2.290428e+01 (terms: 1.684e+01, 3.914e+00, 2.136e+00, 1.123e-02)\n",
            "[MCLES] Iter 4/30\n",
            "  Obj = 2.057246e+01 (terms: 1.349e+01, 4.640e+00, 2.432e+00, 1.076e-02)\n",
            "[MCLES] Iter 5/30\n",
            "  Obj = 1.950549e+01 (terms: 1.187e+01, 5.029e+00, 2.598e+00, 1.043e-02)\n",
            "[MCLES] Iter 6/30\n",
            "  Obj = 1.891264e+01 (terms: 1.087e+01, 5.302e+00, 2.732e+00, 1.012e-02)\n",
            "[MCLES] Iter 7/30\n",
            "  Obj = 1.847269e+01 (terms: 1.013e+01, 5.498e+00, 2.838e+00, 9.845e-03)\n",
            "[MCLES] Iter 8/30\n",
            "  Obj = 1.817083e+01 (terms: 9.585e+00, 5.648e+00, 2.928e+00, 9.605e-03)\n",
            "[MCLES] Iter 9/30\n",
            "  Obj = 1.795104e+01 (terms: 9.172e+00, 5.764e+00, 3.005e+00, 9.398e-03)\n",
            "[MCLES] Iter 10/30\n",
            "  Obj = 1.778925e+01 (terms: 8.850e+00, 5.859e+00, 3.071e+00, 9.218e-03)\n",
            "[MCLES] Converged at iteration 10, rel_change=9.0129e-03\n",
            "Result [ACC, NMI, PUR] = [0.76666667 0.6807561  0.76666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7IIWSssvjQ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}