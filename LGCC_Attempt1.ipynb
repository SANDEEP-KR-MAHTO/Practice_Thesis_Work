{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install node2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vus6QogBEED7",
        "outputId": "5c8e56c4-c1e7-46c7-d486-d39813c1f9ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: node2vec in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from node2vec) (4.4.0)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from node2vec) (1.5.3)\n",
            "Requirement already satisfied: networkx<4.0.0,>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from node2vec) (3.6.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from node2vec) (1.26.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from node2vec) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install munkres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_COjRHLJBmR",
        "outputId": "73674993-35e9-492d-b88a-9481d0e5bfcd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: munkres in /usr/local/lib/python3.12/dist-packages (1.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G5jzBpWYDOTJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import KMeans\n",
        "from node2vec import Node2Vec\n",
        "import networkx as nx\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile metrics.py\n",
        "\n",
        "\n",
        "\n",
        "from munkres import Munkres\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def cal_clustering_acc(true_label, pred_label):\n",
        "    # code from https://github.com/hyzhang98/AdaGAE\n",
        "    l1 = list(set(true_label))\n",
        "    numclass1 = len(l1)\n",
        "\n",
        "    l2 = list(set(pred_label))\n",
        "    numclass2 = len(l2)\n",
        "    if numclass1 != numclass2:\n",
        "        print('Class Not equal, Error!!!!')\n",
        "        return 0\n",
        "\n",
        "    cost = np.zeros((numclass1, numclass2), dtype=int)\n",
        "    for i, c1 in enumerate(l1):\n",
        "        mps = [i1 for i1, e1 in enumerate(true_label) if e1 == c1]\n",
        "        for j, c2 in enumerate(l2):\n",
        "            mps_d = [i1 for i1 in mps if pred_label[i1] == c2]\n",
        "\n",
        "            cost[i][j] = len(mps_d)\n",
        "\n",
        "    # match two clustering results by Munkres algorithm\n",
        "    m = Munkres()\n",
        "    cost = cost.__neg__().tolist()\n",
        "\n",
        "    indexes = m.compute(cost)\n",
        "\n",
        "    # get the match results\n",
        "    new_predict = np.zeros(len(pred_label))\n",
        "    for i, c in enumerate(l1):\n",
        "        # correponding label in l2:\n",
        "        c2 = l2[indexes[i][1]]\n",
        "\n",
        "        # ai is the index with label==c2 in the pred_label list\n",
        "        ai = [ind for ind, elm in enumerate(pred_label) if elm == c2]\n",
        "        new_predict[ai] = c\n",
        "\n",
        "    acc = metrics.accuracy_score(true_label, new_predict)\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klAG-PyXJHmw",
        "outputId": "cff370bd-deca-49b4-9cac-0bc3f6c7b5ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing metrics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lgcc.py\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from node2vec import Node2Vec\n",
        "import networkx as nx\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "\n",
        "def construct_knn_graph(X, k=15, metric=\"cosine\", sigma=1.0):\n",
        "    \"\"\"\n",
        "    Construct k-NN similarity graph for one view\n",
        "    \"\"\"\n",
        "    n = X.shape[0]\n",
        "\n",
        "    if metric == \"cosine\":\n",
        "        X = normalize(X)\n",
        "        sim = np.dot(X, X.T)\n",
        "        A = np.zeros((n, n))\n",
        "        for i in range(n):\n",
        "            idx = np.argsort(sim[i])[-(k + 1):-1]\n",
        "            A[i, idx] = sim[i, idx]\n",
        "    else:\n",
        "        knn = kneighbors_graph(X, k, mode='distance', include_self=False)\n",
        "        distances = knn.toarray()\n",
        "        A = np.exp(-(distances ** 2) / (2 * sigma ** 2))\n",
        "        A[distances == 0] = 0\n",
        "\n",
        "    # Symmetrize\n",
        "    A = 0.5 * (A + A.T)\n",
        "    return A\n",
        "\n",
        "\n",
        "def adaptive_graph_fusion(A_list, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Adaptive consensus graph fusion\n",
        "    \"\"\"\n",
        "    V = len(A_list)\n",
        "    A_bar = sum(A_list) / V\n",
        "\n",
        "    weights = np.zeros(V)\n",
        "    for v in range(V):\n",
        "        weights[v] = 1.0 / (np.linalg.norm(A_list[v] - A_bar, 'fro') + eps)\n",
        "\n",
        "    weights = weights / np.sum(weights)\n",
        "\n",
        "    A_consensus = np.zeros_like(A_list[0])\n",
        "    for v in range(V):\n",
        "        A_consensus += weights[v] * A_list[v]\n",
        "\n",
        "    return A_consensus, weights\n",
        "\n",
        "\n",
        "def node2vec_embedding(A, dim=128, p=1, q=1):\n",
        "    \"\"\"\n",
        "    Node2Vec embedding on consensus graph\n",
        "    \"\"\"\n",
        "    G = nx.from_numpy_array(A)\n",
        "\n",
        "    node2vec = Node2Vec(\n",
        "        G,\n",
        "        dimensions=dim,\n",
        "        walk_length=30,\n",
        "        num_walks=200,\n",
        "        p=p,\n",
        "        q=q,\n",
        "        workers=4,\n",
        "        quiet=True\n",
        "    )\n",
        "\n",
        "    model = node2vec.fit(window=10, min_count=1)\n",
        "    Z = np.array([model.wv[str(i)] for i in range(A.shape[0])])\n",
        "    return Z\n",
        "\n",
        "\n",
        "def LGCC(X_views, n_clusters, k=15, metric_list=None, p=1, q=1):\n",
        "    \"\"\"\n",
        "    Lightweight Graph-based Consensus Clustering (LGCC)\n",
        "\n",
        "    Parameters:\n",
        "        X_views: list of feature matrices (n x d_v)\n",
        "        n_clusters: number of clusters\n",
        "    \"\"\"\n",
        "    if metric_list is None:\n",
        "        metric_list = [\"cosine\"] * len(X_views)\n",
        "\n",
        "    # 1. View-wise graph construction\n",
        "    A_views = []\n",
        "    for X, metric in zip(X_views, metric_list):\n",
        "        A = construct_knn_graph(X, k=k, metric=metric)\n",
        "        A_views.append(A)\n",
        "\n",
        "    # 2. Adaptive consensus graph fusion\n",
        "    A_consensus, weights = adaptive_graph_fusion(A_views)\n",
        "\n",
        "    # 3. Node2Vec embedding\n",
        "    Z = node2vec_embedding(A_consensus, p=p, q=q)\n",
        "\n",
        "    # 4. K-means clustering\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "    labels = kmeans.fit_predict(Z)\n",
        "\n",
        "    return labels, weights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlAp0kDfE7Yz",
        "outputId": "4af78013-228c-420d-8b35-9e034eacf588"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lgcc.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBvBNq6QK5n6",
        "outputId": "a08caf03-5ca2-46fa-b512-8ce72022dc96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as scio\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score"
      ],
      "metadata": {
        "id": "-taUb-4KJm94"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_lgcc.py\n",
        "\n",
        "import numpy as np\n",
        "from lgcc import LGCC\n",
        "import scipy.io as scio\n",
        "from metrics import cal_clustering_acc\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "\n",
        "def evaluate_clustering(y_true, y_pred):\n",
        "    acc = cal_clustering_acc(y_true, y_pred)\n",
        "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
        "    ari = adjusted_rand_score(y_true, y_pred)\n",
        "    return acc, nmi, ari\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # -------- Load dataset (same style as CGL) --------\n",
        "    data = scio.loadmat(\"100Leaves.mat\")\n",
        "\n",
        "    label_key = 'y' if 'y' in data.keys() else 'Y'\n",
        "    y_true = data[label_key].reshape(-1)\n",
        "\n",
        "    X = data['X']          # shape: (1, V)\n",
        "    view_num = X.shape[1]\n",
        "\n",
        "    X_views = []\n",
        "    for v in range(view_num):\n",
        "        X_views.append(X[0][v])\n",
        "\n",
        "    # -------- Parameters --------\n",
        "    n_clusters = len(np.unique(y_true))\n",
        "    k = 15\n",
        "    p = 0.5\n",
        "    q = 2\n",
        "\n",
        "    # -------- Run LGCC --------\n",
        "    labels, view_weights = LGCC(\n",
        "        X_views,\n",
        "        n_clusters=n_clusters,\n",
        "        k=k,\n",
        "        metric_list=[\"cosine\"] * view_num,\n",
        "        p=p,\n",
        "        q=q\n",
        "    )\n",
        "\n",
        "    # -------- Evaluation --------\n",
        "    acc, nmi, ari = evaluate_clustering(y_true, labels)\n",
        "\n",
        "    print(\"LGCC Results\")\n",
        "    print(f\"ACC: {acc:.4f}\")\n",
        "    print(f\"NMI: {nmi:.4f}\")\n",
        "    print(f\"ARI: {ari:.4f}\")\n",
        "    print(\"View Weights:\", view_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTq9PW27JeGE",
        "outputId": "b797f684-2f8f-45b8-d1f2-c2388edfa703"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_lgcc.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lgcc.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XzLmmtMJu44",
        "outputId": "51a1afbb-65ca-4072-d946-b339ef527916"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGCC Results\n",
            "ACC: 0.6831\n",
            "NMI: 0.8374\n",
            "ARI: 0.5728\n",
            "View Weights: [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6U8bxeQeKOQB"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}