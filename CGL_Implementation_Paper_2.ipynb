{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import eigh as largest_eigh\n",
        "import scipy.io as scio\n",
        "from scipy import sparse\n",
        "from sklearn import cluster\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.neighbors import kneighbors_graph\n"
      ],
      "metadata": {
        "id": "XwGlYux6Z_g4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install munkres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZU5xc6Nf-F-",
        "outputId": "ab04480e-d979-49ad-a2cc-eed0cfb6c1c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting munkres\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\n",
            "Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: munkres\n",
            "Successfully installed munkres-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0tIY38LZytl",
        "outputId": "57863200-171a-4a9b-fe83-2bcf1523c572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing metrics.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile metrics.py\n",
        "\n",
        "\n",
        "\n",
        "from munkres import Munkres\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def cal_clustering_acc(true_label, pred_label):\n",
        "    # code from https://github.com/hyzhang98/AdaGAE\n",
        "    l1 = list(set(true_label))\n",
        "    numclass1 = len(l1)\n",
        "\n",
        "    l2 = list(set(pred_label))\n",
        "    numclass2 = len(l2)\n",
        "    if numclass1 != numclass2:\n",
        "        print('Class Not equal, Error!!!!')\n",
        "        return 0\n",
        "\n",
        "    cost = np.zeros((numclass1, numclass2), dtype=int)\n",
        "    for i, c1 in enumerate(l1):\n",
        "        mps = [i1 for i1, e1 in enumerate(true_label) if e1 == c1]\n",
        "        for j, c2 in enumerate(l2):\n",
        "            mps_d = [i1 for i1 in mps if pred_label[i1] == c2]\n",
        "\n",
        "            cost[i][j] = len(mps_d)\n",
        "\n",
        "    # match two clustering results by Munkres algorithm\n",
        "    m = Munkres()\n",
        "    cost = cost.__neg__().tolist()\n",
        "\n",
        "    indexes = m.compute(cost)\n",
        "\n",
        "    # get the match results\n",
        "    new_predict = np.zeros(len(pred_label))\n",
        "    for i, c in enumerate(l1):\n",
        "        # correponding label in l2:\n",
        "        c2 = l2[indexes[i][1]]\n",
        "\n",
        "        # ai is the index with label==c2 in the pred_label list\n",
        "        ai = [ind for ind, elm in enumerate(pred_label) if elm == c2]\n",
        "        new_predict[ai] = c\n",
        "\n",
        "    acc = metrics.accuracy_score(true_label, new_predict)\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile metrics_extended.py\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from munkres import Munkres\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Clustering Accuracy (same as before)\n",
        "# -------------------------------\n",
        "def cal_clustering_acc(true_label, pred_label):\n",
        "    l1 = list(set(true_label))\n",
        "    numclass1 = len(l1)\n",
        "    l2 = list(set(pred_label))\n",
        "    numclass2 = len(l2)\n",
        "    if numclass1 != numclass2:\n",
        "        print('⚠️ Class numbers differ, Hungarian matching may be partial.')\n",
        "    cost = np.zeros((numclass1, numclass2), dtype=int)\n",
        "    for i, c1 in enumerate(l1):\n",
        "        mps = [i1 for i1, e1 in enumerate(true_label) if e1 == c1]\n",
        "        for j, c2 in enumerate(l2):\n",
        "            mps_d = [i1 for i1 in mps if pred_label[i1] == c2]\n",
        "            cost[i][j] = len(mps_d)\n",
        "    m = Munkres()\n",
        "    cost = (-cost).tolist()\n",
        "    indexes = m.compute(cost)\n",
        "    new_predict = np.zeros(len(pred_label))\n",
        "    for i, c in enumerate(l1):\n",
        "        c2 = l2[indexes[i][1]]\n",
        "        ai = [ind for ind, elm in enumerate(pred_label) if elm == c2]\n",
        "        new_predict[ai] = c\n",
        "    acc = metrics.accuracy_score(true_label, new_predict)\n",
        "    return acc\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Normalized Mutual Information (NMI)\n",
        "# -------------------------------\n",
        "def cal_nmi(true_label, pred_label):\n",
        "    return metrics.normalized_mutual_info_score(true_label, pred_label, average_method='arithmetic')\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Adjusted Rand Index (ARI)\n",
        "# -------------------------------\n",
        "def cal_ari(true_label, pred_label):\n",
        "    return metrics.adjusted_rand_score(true_label, pred_label)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Purity\n",
        "# -------------------------------\n",
        "def cal_purity(true_label, pred_label):\n",
        "    # contingency matrix (rows=true, cols=pred)\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(true_label, pred_label)\n",
        "    # Purity = sum of max value in each predicted cluster / total samples\n",
        "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Precision, Recall, F1-score\n",
        "# -------------------------------\n",
        "def cal_prf(true_label, pred_label):\n",
        "    # You need to first align predicted labels using accuracy matching\n",
        "    acc = cal_clustering_acc(true_label, pred_label)\n",
        "    # For precision/recall/F1, we can compute macro-averaged\n",
        "    precision = metrics.precision_score(true_label, pred_label, average='macro', zero_division=0)\n",
        "    recall = metrics.recall_score(true_label, pred_label, average='macro', zero_division=0)\n",
        "    f1 = metrics.f1_score(true_label, pred_label, average='macro', zero_division=0)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# -------------------------------\n",
        "# 6. All metrics together (main utility)\n",
        "# -------------------------------\n",
        "def evaluate_clustering(true_label, pred_label):\n",
        "    acc = cal_clustering_acc(true_label, pred_label)\n",
        "    nmi = cal_nmi(true_label, pred_label)\n",
        "    ari = cal_ari(true_label, pred_label)\n",
        "    purity = cal_purity(true_label, pred_label)\n",
        "    precision, recall, f1 = cal_prf(true_label, pred_label)\n",
        "\n",
        "    results = {\n",
        "        'ACC': acc,\n",
        "        'NMI': nmi,\n",
        "        'ARI': ari,\n",
        "        'Purity': purity,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-score': f1\n",
        "    }\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example test\n",
        "    true = np.array([1,1,2,2,3,3])\n",
        "    pred = np.array([2,2,1,1,3,3])  # permuted clusters\n",
        "    res = evaluate_clustering(true, pred)\n",
        "    for k,v in res.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "_vawmIs_eFDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdaa9808-f7d4-4f70-f4f4-1ad324710f98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing metrics_extended.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_lw--PCte5l2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cgl.py\n",
        "\n",
        "import numpy as np\n",
        "from metrics import cal_clustering_acc\n",
        "from metrics_extended import evaluate_clustering\n",
        "from munkres import Munkres\n",
        "from scipy.linalg import eigh as largest_eigh\n",
        "import scipy.io as scio\n",
        "from scipy import sparse\n",
        "from sklearn import cluster\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "def prox_weight_tensor_nuclear_norm(Y, C):\n",
        "    # calculate the weighted tensor nuclear norm\n",
        "    # min_X ||X||_w* + 0.5||X - Y||_F^2\n",
        "    n1, n2, n3 = np.shape(Y)\n",
        "    X = np.zeros((n1, n2, n3), dtype=complex)\n",
        "    # Y = np.fft.fft(Y, n3)\n",
        "    Y = np.fft.fftn(Y)\n",
        "    # Y = np.fft.fftn(Y, s=[n1, n2, n3])\n",
        "    eps = 1e-6\n",
        "    for i in range(n3):\n",
        "        U, S, V = np.linalg.svd(Y[:, :, i], full_matrices=False)\n",
        "        temp = np.power(S - eps, 2) - 4 * (C - eps * S)\n",
        "        ind = np.where(temp > 0)\n",
        "        ind = np.array(ind)\n",
        "        r = np.max(ind.shape)\n",
        "        if np.min(ind.shape) == 0:\n",
        "            r = 0\n",
        "        if r >= 1:\n",
        "            temp2 = S[ind] - eps + np.sqrt(temp[ind])\n",
        "            S = temp2.reshape(temp2.size, )\n",
        "            X[:, :, i] = np.dot(np.dot(U[:, 0:r], np.diag(S)), V[:, 0:r].T)\n",
        "    newX = np.fft.ifftn(X)\n",
        "    # newX = np.fft.ifftn(X, s=[n1, n2, n3])\n",
        "    # newX = np.fft.ifft(X, n3)\n",
        "\n",
        "    return np.real(newX)\n",
        "\n",
        "\n",
        "def cal_knn_graph(distance, neighbor_num):\n",
        "    # construct a knn graph\n",
        "    neighbors_graph = kneighbors_graph(\n",
        "        distance, neighbor_num, mode='connectivity', include_self=False)\n",
        "    W = 0.5 * (neighbors_graph + neighbors_graph.T)\n",
        "    return W\n",
        "\n",
        "\n",
        "\n",
        "def consensus_graph_learning(A, cluster_num, lambda_1, rho, iteration_num):\n",
        "    # optimize the consensus graph learning problem\n",
        "    # min_H, Z 0.5||A - H'H||_F^2 + 0.5||Z - hatHhatH'||_F^2 + ||Z||_w*\n",
        "    # s.t. H'H = I_k\n",
        "    sample_num, sample_num, view_num = np.shape(A)\n",
        "    # initial variables\n",
        "    H = np.zeros((sample_num, cluster_num, view_num))\n",
        "    HH = np.zeros((sample_num, sample_num, view_num))\n",
        "    hatH = np.zeros((sample_num, cluster_num, view_num))\n",
        "    hatHH = np.zeros((sample_num, sample_num, view_num))\n",
        "    Q = np.zeros((sample_num, sample_num, view_num))\n",
        "    Z = np.zeros((sample_num, sample_num, view_num))\n",
        "    obj = np.zeros((iteration_num, 1))\n",
        "    # loop\n",
        "    for iter in range(iteration_num):\n",
        "        # update H\n",
        "        temp = np.zeros((sample_num, sample_num, view_num))\n",
        "        G = np.zeros((sample_num, sample_num, view_num))\n",
        "        for view in range(view_num):\n",
        "            temp[:, :, view] = np.dot(\n",
        "                np.dot(Q[:, :, view], 0.5 * (Z[:, :, view] + Z[:, :, view].T) - 0.5 * hatHH[:, :, view])\n",
        "                , Q[:, :, view]\n",
        "            )\n",
        "            G[:, :, view] = lambda_1 * A[:, :, view] + temp[:, :, view]\n",
        "            _, H[:, :, view] = largest_eigh(\n",
        "                G[:, :, view], subset_by_index=[sample_num - cluster_num, sample_num - 1]\n",
        "            )\n",
        "            HH[:, :, view] = np.dot(H[:, :, view], H[:, :, view].T)\n",
        "            Q[:, :, view] = np.diag(1 / np.sqrt(np.diag(HH[:, :, view])))\n",
        "            hatH[:, :, view] = np.dot(Q[:, :, view], H[:, :, view])\n",
        "            hatHH[:, :, view] = np.dot(hatH[:, :, view], hatH[:, :, view].T)\n",
        "        # update Z\n",
        "        hatHH2 = hatHH.transpose((0, 2, 1))\n",
        "        Z2 = prox_weight_tensor_nuclear_norm(hatHH2, rho)\n",
        "        Z = Z2.transpose((0, 2, 1))\n",
        "        # update obj\n",
        "        f = np.zeros((view_num, 1))\n",
        "        for view in range(view_num):\n",
        "            f[view] = 0.5 * lambda_1 * np.linalg.norm(A[:, :, view] - HH[:, :, view], ord='fro') + \\\n",
        "                      0.5 * np.linalg.norm(Z[:, :, view] - hatHH[:, :, view], ord='fro')\n",
        "        obj[iter] = np.sum(f)\n",
        "\n",
        "    # construct knn graph\n",
        "    distance = np.zeros((sample_num, sample_num))\n",
        "    for view in range(view_num):\n",
        "        distance += hatHH[:, :, view]\n",
        "    W = cal_knn_graph(1 - distance, 15)\n",
        "    # perform spectral clustering\n",
        "    laplacian = sparse.csgraph.laplacian(W, normed=True)\n",
        "    _, vec = sparse.linalg.eigsh(sparse.identity(\n",
        "        laplacian.shape[0]) - laplacian, cluster_num, sigma=None, which='LA')\n",
        "    embedding = normalize(vec)\n",
        "    est = cluster.KMeans(n_clusters=cluster_num, n_init=\"auto\").fit(embedding)\n",
        "    # reture results\n",
        "    return W, est.labels_\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    precomputed = 1\n",
        "    if precomputed != 1:\n",
        "        # precomputed graph with the neighbor graph learning method\n",
        "        data_matrix = scio.loadmat('MSRCV1_A.mat')\n",
        "        ground_truth = data_matrix['Y']\n",
        "        A = data_matrix['A']\n",
        "    else:\n",
        "        # knn graph via sklearn.neighbors.kneighbors_graph\n",
        "        data_matrix = scio.loadmat('MSRCV1_X.mat')\n",
        "        ground_truth = data_matrix['Y']\n",
        "        features = data_matrix['X']\n",
        "        # construct view_specific knn graph\n",
        "        view_num = features.shape[1]\n",
        "        sample_num, _ = features[0][0].shape\n",
        "        A = np.zeros((sample_num, sample_num, view_num))\n",
        "        for view in range(view_num):\n",
        "            knn_graph = cal_knn_graph(features[0][view], neighbor_num=15)\n",
        "            S = sparse.identity(knn_graph.shape[0]) - sparse.csgraph.laplacian(knn_graph, normed=True).toarray()\n",
        "            A[:, :, view] = S\n",
        "\n",
        "    ground_truth = ground_truth.reshape(np.max(ground_truth.shape), )\n",
        "    cluster_num = 7\n",
        "    parameter_lambda = [1, 5, 10, 50, 100, 500, 1000, 5000]\n",
        "    parameter_rho = [1, 5, 10, 50, 100, 500, 1000, 5000]\n",
        "    ACC = np.zeros((8, 8))\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            W, predict_label = consensus_graph_learning(A, cluster_num, parameter_lambda[i], parameter_rho[j], 100)\n",
        "            predict_label = predict_label + 1\n",
        "\n",
        "\n",
        "            results = evaluate_clustering(ground_truth, predict_label)\n",
        "            print(f\"λ={parameter_lambda[i]}, ρ={parameter_rho[j]} -> \"\n",
        "                  f\"ACC={results['ACC']:.4f}, NMI={results['NMI']:.4f}, \"\n",
        "                  f\"Purity={results['Purity']:.4f}, ARI={results['ARI']:.4f}, \"\n",
        "                  f\"F1={results['F1-score']:.4f}\")\n",
        "            ACC[i, j] = results['ACC']\n",
        "\n",
        "    print('max clustering accuracy: {}'.format(ACC.max()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUHDeMVWaO0Y",
        "outputId": "39a16923-ca00-4b82-d8c9-50c31960c0a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cgl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python cgl.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clwx0_SGair3",
        "outputId": "4bca7576-a844-4261-a3be-93fcb41c625e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "λ=1, ρ=1 -> ACC=0.8667, NMI=0.7609, Purity=0.8667, ARI=0.7301, F1=0.0182\n",
            "λ=1, ρ=5 -> ACC=0.8667, NMI=0.7613, Purity=0.8667, ARI=0.7311, F1=0.0097\n",
            "λ=1, ρ=10 -> ACC=0.8667, NMI=0.7585, Purity=0.8667, ARI=0.7299, F1=0.1475\n",
            "λ=1, ρ=50 -> ACC=0.8667, NMI=0.7613, Purity=0.8667, ARI=0.7311, F1=0.0189\n",
            "λ=1, ρ=100 -> ACC=0.8667, NMI=0.7630, Purity=0.8667, ARI=0.7302, F1=0.0091\n",
            "λ=1, ρ=500 -> ACC=0.8667, NMI=0.7634, Purity=0.8667, ARI=0.7292, F1=0.0186\n",
            "λ=1, ρ=1000 -> ACC=0.8667, NMI=0.7613, Purity=0.8667, ARI=0.7311, F1=0.2608\n",
            "λ=1, ρ=5000 -> ACC=0.8667, NMI=0.7613, Purity=0.8667, ARI=0.7311, F1=0.3726\n",
            "λ=5, ρ=1 -> ACC=0.8667, NMI=0.7613, Purity=0.8667, ARI=0.7311, F1=0.1597\n",
            "λ=5, ρ=5 -> ACC=0.8667, NMI=0.7585, Purity=0.8667, ARI=0.7299, F1=0.0333\n",
            "λ=5, ρ=10 -> ACC=0.8714, NMI=0.7650, Purity=0.8714, ARI=0.7372, F1=0.0300\n",
            "λ=5, ρ=50 -> ACC=0.8667, NMI=0.7609, Purity=0.8667, ARI=0.7301, F1=0.0245\n",
            "λ=5, ρ=100 -> ACC=0.8667, NMI=0.7634, Purity=0.8667, ARI=0.7292, F1=0.1295\n",
            "λ=5, ρ=500 -> ACC=0.8667, NMI=0.7609, Purity=0.8667, ARI=0.7301, F1=0.1053\n",
            "λ=5, ρ=1000 -> ACC=0.8667, NMI=0.7581, Purity=0.8667, ARI=0.7286, F1=0.0235\n",
            "λ=5, ρ=5000 -> ACC=0.8667, NMI=0.7609, Purity=0.8667, ARI=0.7301, F1=0.0192\n",
            "λ=10, ρ=1 -> ACC=0.8667, NMI=0.7585, Purity=0.8667, ARI=0.7299, F1=0.0092\n",
            "λ=10, ρ=5 -> ACC=0.8667, NMI=0.7585, Purity=0.8667, ARI=0.7299, F1=0.0182\n",
            "λ=10, ρ=10 -> ACC=0.8762, NMI=0.7680, Purity=0.8762, ARI=0.7429, F1=0.0243\n",
            "λ=10, ρ=50 -> ACC=0.8762, NMI=0.7680, Purity=0.8762, ARI=0.7429, F1=0.0142\n",
            "λ=10, ρ=100 -> ACC=0.8714, NMI=0.7650, Purity=0.8714, ARI=0.7372, F1=0.0300\n",
            "λ=10, ρ=500 -> ACC=0.8762, NMI=0.7680, Purity=0.8762, ARI=0.7429, F1=0.1418\n",
            "λ=10, ρ=1000 -> ACC=0.8762, NMI=0.7680, Purity=0.8762, ARI=0.7429, F1=0.1426\n",
            "λ=10, ρ=5000 -> ACC=0.8857, NMI=0.7873, Purity=0.8857, ARI=0.7620, F1=0.1724\n",
            "λ=50, ρ=1 -> ACC=0.9048, NMI=0.8249, Purity=0.9048, ARI=0.7982, F1=0.1813\n",
            "λ=50, ρ=5 -> ACC=0.9000, NMI=0.8147, Purity=0.9000, ARI=0.7889, F1=0.5186\n",
            "λ=50, ρ=10 -> ACC=0.9000, NMI=0.8147, Purity=0.9000, ARI=0.7889, F1=0.0046\n",
            "λ=50, ρ=50 -> ACC=0.9000, NMI=0.8147, Purity=0.9000, ARI=0.7889, F1=0.0194\n",
            "λ=50, ρ=100 -> ACC=0.9048, NMI=0.8249, Purity=0.9048, ARI=0.7982, F1=0.1522\n",
            "λ=50, ρ=500 -> ACC=0.9000, NMI=0.8147, Purity=0.9000, ARI=0.7889, F1=0.1510\n",
            "λ=50, ρ=1000 -> ACC=0.9048, NMI=0.8249, Purity=0.9048, ARI=0.7982, F1=0.3037\n",
            "λ=50, ρ=5000 -> ACC=0.9048, NMI=0.8309, Purity=0.9048, ARI=0.7992, F1=0.1412\n",
            "λ=100, ρ=1 -> ACC=0.9286, NMI=0.8584, Purity=0.9286, ARI=0.8415, F1=0.0048\n",
            "λ=100, ρ=5 -> ACC=0.9333, NMI=0.8691, Purity=0.9333, ARI=0.8526, F1=0.1379\n",
            "λ=100, ρ=10 -> ACC=0.9286, NMI=0.8584, Purity=0.9286, ARI=0.8415, F1=0.2762\n",
            "λ=100, ρ=50 -> ACC=0.9333, NMI=0.8691, Purity=0.9333, ARI=0.8526, F1=0.4283\n",
            "λ=100, ρ=100 -> ACC=0.9333, NMI=0.8691, Purity=0.9333, ARI=0.8526, F1=0.1244\n",
            "λ=100, ρ=500 -> ACC=0.9333, NMI=0.8691, Purity=0.9333, ARI=0.8526, F1=0.1638\n",
            "λ=100, ρ=1000 -> ACC=0.9333, NMI=0.8691, Purity=0.9333, ARI=0.8526, F1=0.0094\n",
            "λ=100, ρ=5000 -> ACC=0.9333, NMI=0.8691, Purity=0.9333, ARI=0.8526, F1=0.1300\n",
            "λ=500, ρ=1 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.2533\n",
            "λ=500, ρ=5 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.1295\n",
            "λ=500, ρ=10 -> ACC=0.9286, NMI=0.8625, Purity=0.9286, ARI=0.8405, F1=0.1294\n",
            "λ=500, ρ=50 -> ACC=0.9143, NMI=0.8394, Purity=0.9143, ARI=0.8132, F1=0.0088\n",
            "λ=500, ρ=100 -> ACC=0.9286, NMI=0.8625, Purity=0.9286, ARI=0.8405, F1=0.0135\n",
            "λ=500, ρ=500 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.0088\n",
            "λ=500, ρ=1000 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.0048\n",
            "λ=500, ρ=5000 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.0096\n",
            "λ=1000, ρ=1 -> ACC=0.9190, NMI=0.8414, Purity=0.9190, ARI=0.8200, F1=0.2485\n",
            "λ=1000, ρ=5 -> ACC=0.9095, NMI=0.8345, Purity=0.9095, ARI=0.8049, F1=0.0088\n",
            "λ=1000, ρ=10 -> ACC=0.9190, NMI=0.8451, Purity=0.9190, ARI=0.8218, F1=0.0136\n",
            "λ=1000, ρ=50 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.0134\n",
            "λ=1000, ρ=100 -> ACC=0.9190, NMI=0.8471, Purity=0.9190, ARI=0.8224, F1=0.1539\n",
            "λ=1000, ρ=500 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.2675\n",
            "λ=1000, ρ=1000 -> ACC=0.9190, NMI=0.8451, Purity=0.9190, ARI=0.8218, F1=0.1536\n",
            "λ=1000, ρ=5000 -> ACC=0.9238, NMI=0.8521, Purity=0.9238, ARI=0.8310, F1=0.1238\n",
            "λ=5000, ρ=1 -> ACC=0.9238, NMI=0.8559, Purity=0.9238, ARI=0.8284, F1=0.0046\n",
            "λ=5000, ρ=5 -> ACC=0.9238, NMI=0.8564, Purity=0.9238, ARI=0.8303, F1=0.1609\n",
            "λ=5000, ρ=10 -> ACC=0.9286, NMI=0.8620, Purity=0.9286, ARI=0.8383, F1=0.1477\n",
            "λ=5000, ρ=50 -> ACC=0.9190, NMI=0.8457, Purity=0.9190, ARI=0.8193, F1=0.1313\n",
            "λ=5000, ρ=100 -> ACC=0.9286, NMI=0.8667, Purity=0.9286, ARI=0.8394, F1=0.2924\n",
            "λ=5000, ρ=500 -> ACC=0.9238, NMI=0.8559, Purity=0.9238, ARI=0.8284, F1=0.1491\n",
            "λ=5000, ρ=1000 -> ACC=0.9190, NMI=0.8457, Purity=0.9190, ARI=0.8193, F1=0.0095\n",
            "λ=5000, ρ=5000 -> ACC=0.9190, NMI=0.8457, Purity=0.9190, ARI=0.8193, F1=0.0048\n",
            "max clustering accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lprtHEvKajE_"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}